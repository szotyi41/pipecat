#
# Copyright (c) 2024‚Äì2025, Daily
#
# SPDX-License-Identifier: BSD 2-Clause License
#

"""
Val√≥s idej≈± el≈ëad√°s √°t√≠r√°s
===========================

Ez a p√©lda bemutatja, hogyan lehet val√≥s id≈ëben √°t√≠rni egy el≈ëad√°st (hang ‚Üí sz√∂veg).
Az √°t√≠rt sz√∂veg megjelenik a b√∂ng√©sz≈ë fel√ºlet√©n.

Haszn√°lat:
    python examples/foundational/49-realtime-lecture-qa.py

Sz√ºks√©ges k√∂rnyezeti v√°ltoz√≥k:
- GOOGLE_TEST_CREDENTIALS: Google Cloud credentials (STT-hez)
"""

import os

from dotenv import load_dotenv
from loguru import logger

from pipecat.audio.vad.silero import SileroVADAnalyzer
from pipecat.audio.vad.vad_analyzer import VADParams
from pipecat.frames.frames import (
    Frame,
    OutputTransportMessageFrame,
    TranscriptionFrame,
)
from pipecat.pipeline.pipeline import Pipeline
from pipecat.pipeline.runner import PipelineRunner
from pipecat.pipeline.task import PipelineParams, PipelineTask
from pipecat.processors.frame_processor import FrameDirection, FrameProcessor
from pipecat.runner.types import RunnerArguments
from pipecat.runner.utils import create_transport
from pipecat.services.google.stt import GoogleSTTService
from pipecat.transcriptions.language import Language
from pipecat.transports.base_transport import BaseTransport, TransportParams
from pipecat.transports.daily.transport import DailyParams
from pipecat.transports.websocket.fastapi import FastAPIWebsocketParams

load_dotenv(override=True)


class TranscriptDisplayProcessor(FrameProcessor):
    """Elk√ºldi a transzkripci√≥kat a WebRTC fel√ºletre."""
    
    async def process_frame(self, frame: Frame, direction: FrameDirection):
        await super().process_frame(frame, direction)
        
        # TranscriptionFrame k√∂zvetlen√ºl az STT-t≈ël
        if isinstance(frame, TranscriptionFrame):
            # Form√°zott sz√∂veg a fel√ºletre
            text = f"üé§ {frame.text}"
            
            logger.info(f"‚úÖ TranscriptionFrame √©szlelve: {frame.text}")
            
            # OutputTransportMessageFrame k√ºld√©se a b√∂ng√©sz≈ë fel√ºlet√©re
            message_frame = OutputTransportMessageFrame(message={"text": text})
            logger.info(f"üì§ OutputTransportMessageFrame k√ºld√©se: {text}")
            await self.push_frame(message_frame, FrameDirection.DOWNSTREAM)
        
        # Tov√°bb√≠tjuk az eredeti frame-et is
        await self.push_frame(frame, direction)


# Transport param√©terek - csak audio input √©s text output
transport_params = {
    "daily": lambda: DailyParams(
        audio_in_enabled=True,
        audio_out_enabled=False,  # Nincs bot audio
        video_out_enabled=False,  # Nincs bot video
        text_output_enabled=True,  # Text output a transkripci√≥hoz
        vad_analyzer=SileroVADAnalyzer(params=VADParams(stop_secs=0.5)),
    ),
    "twilio": lambda: FastAPIWebsocketParams(
        audio_in_enabled=True,
        audio_out_enabled=False,  # Nincs bot audio
        video_out_enabled=False,  # Nincs bot video
        text_output_enabled=True,  # Text output a transkripci√≥hoz
        vad_analyzer=SileroVADAnalyzer(params=VADParams(stop_secs=0.5)),
    ),
    "webrtc": lambda: TransportParams(
        audio_in_enabled=True,
        audio_out_enabled=False,  # Nincs bot audio
        video_out_enabled=False,  # Nincs bot video
        text_output_enabled=True,  # Text output a transkripci√≥hoz
        vad_analyzer=SileroVADAnalyzer(params=VADParams(stop_secs=0.5)),
    ),
}


async def run_bot(transport: BaseTransport, runner_args: RunnerArguments):
    logger.info("üé§ Val√≥s idej≈± √°t√≠r√°s ind√≠t√°sa...")

    # Szolg√°ltat√°sok inicializ√°l√°sa
    credentials_path = os.getenv("GOOGLE_TEST_CREDENTIALS")
    
    # STT - √°t√≠r√°shoz
    stt = GoogleSTTService(
        params=GoogleSTTService.InputParams(languages=Language.HU, model="chirp_3"),
        credentials_path=credentials_path,
        location="eu",
    )

    # Transcript display processor - elk√ºldi a sz√∂veget a fel√ºletre
    transcript_display = TranscriptDisplayProcessor()

    # Pipeline √∂ssze√°ll√≠t√°sa - STT ‚Üí display ‚Üí output
    pipeline = Pipeline(
        [
            transport.input(),  # Audio input
            stt,  # Speech-to-Text
            transcript_display,  # Transcript megjelen√≠t√©s a fel√ºleten
            transport.output(),  # Text output a fel√ºletre
        ]
    )

    task = PipelineTask(
        pipeline,
        params=PipelineParams(
            enable_metrics=True,
            enable_usage_metrics=True,
        ),
        idle_timeout_secs=runner_args.pipeline_idle_timeout_secs,
    )

    @transport.event_handler("on_client_connected")
    async def on_client_connected(transport, client):
        logger.info("‚úÖ Kliens csatlakozott - √°t√≠r√°s elkezd≈ëd√∂tt")
        logger.info("üí° Az elhangzott sz√∂veg megjelenik a b√∂ng√©sz≈ëben\n")

    @transport.event_handler("on_client_disconnected")
    async def on_client_disconnected(transport, client):
        logger.info("‚ùå Kliens lecsatlakozott")
        await task.cancel()

    runner = PipelineRunner(handle_sigint=runner_args.handle_sigint)

    await runner.run(task)


async def bot(runner_args: RunnerArguments):
    """Main bot entry point compatible with Pipecat Cloud."""
    transport = await create_transport(runner_args, transport_params)
    await run_bot(transport, runner_args)


if __name__ == "__main__":
    from pipecat.runner.run import main

    main()
